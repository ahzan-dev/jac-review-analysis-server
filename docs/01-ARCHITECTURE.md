# System Architecture

## ğŸ—ï¸ High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         USER INPUT                                  â”‚
â”‚  Google Maps URL + max_reviews + analysis_depth                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ENTRY POINT: AnalyzeUrl Walker                   â”‚
â”‚  - Receives parameters                                              â”‚
â”‚  - Spawns FullPipelineAgent                                         â”‚
â”‚  - Returns success + output JSON                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               ORCHESTRATOR: FullPipelineAgent                       â”‚
â”‚  - Coordinates 4 agents sequentially                                â”‚
â”‚  - Builds final output JSON                                         â”‚
â”‚  - Handles errors                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                   â”‚                   â”‚                 â”‚
        â–¼                   â–¼                   â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ AGENT 1:     â”‚    â”‚ AGENT 2:     â”‚    â”‚ AGENT 3:     â”‚  â”‚ AGENT 4:     â”‚
â”‚ DataFetcher  â”‚â”€â”€â”€â–¶â”‚ Sentiment    â”‚â”€â”€â”€â–¶â”‚ Pattern      â”‚â”€â–¶â”‚ Report       â”‚
â”‚              â”‚    â”‚ Analyzer     â”‚    â”‚ Analyzer     â”‚  â”‚ Generator    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                   â”‚                   â”‚                 â”‚
        â–¼                   â–¼                   â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Business   â”‚    â”‚   Reviews    â”‚    â”‚   Analysis   â”‚  â”‚    Report    â”‚
â”‚     Node     â”‚    â”‚   Analyzed   â”‚    â”‚     Node     â”‚  â”‚     Node     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“¦ Component Breakdown

### 1. Entry Point Layer

#### **AnalyzeUrl Walker** (`main.jac`)

**Purpose**: Main API endpoint for the system

**Inputs**:

```typescript
{
  url: string; // Google Maps URL
  max_reviews: number; // Max reviews to fetch (default: 100)
  analysis_depth: string; // "basic" | "standard" | "deep"
  api_key: string; // SERP API key (optional)
  force_mock: boolean; // Use mock data (default: false)
}
```

**Outputs**:

```typescript
{
  success: boolean;
  data_source: string; // "mock" or "serpapi"
  output: {
    // Complete analysis JSON (see 06-JSON-OUTPUT-STRUCTURE.md)
  }
  error: string; // If success = false
}
```

**Responsibilities**:

- Validate input parameters
- Spawn FullPipelineAgent
- Handle success/error responses
- Report final output

---

### 2. Orchestration Layer

#### **FullPipelineAgent Walker** (`walkers.jac`)

**Purpose**: Coordinates all 4 agents and builds final output

**Data Flow**:

```
START
  â”‚
  â”œâ”€â–¶ Parse URL
  â”‚
  â”œâ”€â–¶ STAGE 1: DataFetcherAgent
  â”‚   â””â”€â–¶ Creates: Business node + Review nodes
  â”‚
  â”œâ”€â–¶ STAGE 2: SentimentAnalyzerAgent
  â”‚   â””â”€â–¶ Updates: Review nodes with sentiment data
  â”‚
  â”œâ”€â–¶ STAGE 3: PatternAnalyzerAgent
  â”‚   â””â”€â–¶ Creates: Analysis node + Theme nodes
  â”‚
  â”œâ”€â–¶ STAGE 4: ReportGeneratorAgent
  â”‚   â””â”€â–¶ Creates: Report node
  â”‚
  â”œâ”€â–¶ Build output JSON
  â”‚
END
```

**Error Handling**:

- Each stage checks if previous stage succeeded
- If any stage fails, pipeline stops
- Error message propagated to user

**State Management**:

```jac
has business_id: str = "";
has status: str = "pending";  // "pending" | "completed" | "failed"
has stages_completed: list = [];
has data_source: str = "";
has output: dict = {};
has error: str = "";
```

---

### 3. Agent Layer

#### **Agent 1: DataFetcherAgent**

**Purpose**: Fetch business and review data

**Process**:

```
1. Parse Google Maps URL
   â”œâ”€ Extract data_id (0x...:0x...)
   â”œâ”€ Extract place_name
   â””â”€ Validate URL

2. Determine data source
   â”œâ”€ If SERPAPI_KEY exists â†’ use SERP API
   â””â”€ Else â†’ use mock data

3. Fetch place details
   â”œâ”€ Call: https://serpapi.com/search (place)
   â””â”€ Create Business node with:
       - name, address, phone, website
       - rating, total_reviews
       - business_type (from Google)
       - coordinates, opening_hours
       - photos_count

4. Detect business type
   â”œâ”€ Map Google type â†’ normalized type
   â””â”€ RESTAURANT | HOTEL | RETAIL | etc.

5. Fetch reviews
   â”œâ”€ Call: https://serpapi.com/search (reviews)
   â”œâ”€ Paginate until max_reviews reached
   â””â”€ Create Review nodes with:
       - author, rating, text
       - date, relative_date
       - likes, owner_response

6. Connect nodes
   â”œâ”€ Business ++> Review (HasReview edge)
   â””â”€ Update Business.status = "fetched"
```

**Output**:

- `business: Business` - Business node reference
- `reviews_fetched: int` - Count of reviews fetched
- `status: str` - "completed" | "failed"
- `data_source: str` - "serpapi" | "mock"

---

#### **Agent 2: SentimentAnalyzerAgent**

**Purpose**: Analyze reviews for sentiment, themes, emotions

**Process**:

```
1. Find target Business node
   â””â”€ Navigate graph: root --> Business

2. Get business type and theme definitions
   â”œâ”€ business_type_normalized (e.g., "RESTAURANT")
   â””â”€ Get allowed themes from THEME_DEFINITIONS

3. Get unanalyzed reviews
   â”œâ”€ Business --> Review (where analyzed = false)
   â””â”€ Group into batches of 5

4. Process each batch
   â”œâ”€ Build batch input:
   â”‚   {index: 0, rating: 5, text: "..."}
   â”‚   {index: 1, rating: 4, text: "..."}
   â”‚   ...
   â”‚
   â”œâ”€ Call LLM: analyze_reviews_batch()
   â”‚   â””â”€ Returns: BatchReviewAnalysis
   â”‚       â””â”€ reviews: [SingleReviewAnalysis]
   â”‚
   â””â”€ Update Review nodes:
       - sentiment ("positive" | "negative" | "neutral" | "mixed")
       - sentiment_score (-1.0 to 1.0)
       - themes (list of main themes)
       - sub_themes (dict: theme â†’ [sub-theme names])
       - keywords (list of key phrases)
       - emotion (primary emotion)
       - analyzed = true

5. Track statistics
   â”œâ”€ sentiment_counts: {positive, negative, neutral, mixed}
   â””â”€ all_themes: {theme: {count, positive, negative, ...}}
```

**LLM Call**: `analyze_reviews_batch()`

**Output**:

- `analyzed_count: int` - Total reviews analyzed
- `sentiment_counts: dict` - Sentiment distribution
- `all_themes: dict` - Theme statistics
- `status: str` - "completed"

---

#### **Agent 3: PatternAnalyzerAgent**

**Purpose**: Identify patterns, calculate health score, generate SWOT

**Process**:

```
1. Find target Business node
   â””â”€ Get all analyzed reviews

2. Calculate statistics
   â”œâ”€ Sentiment distribution (counts, percentages)
   â”œâ”€ Average sentiment score
   â”œâ”€ Rating distribution {1: n, 2: n, ...}
   â”œâ”€ Average review length
   â”œâ”€ Photos count, response rate
   â””â”€ Store in stats dict

3. Build theme analysis
   â”œâ”€ For each review's themes:
   â”‚   â”œâ”€ Count mentions
   â”‚   â”œâ”€ Track sentiment per theme
   â”‚   â”œâ”€ Collect sub-theme data
   â”‚   â””â”€ Save positive/negative quotes
   â”‚
   â””â”€ For each sub-theme:
       â”œâ”€ Calculate sentiment average
       â”œâ”€ Determine verdict (excellent, good, needs_attention, poor)
       â””â”€ Sort by mention count

4. Calculate trends
   â”œâ”€ Group reviews by month (parse dates)
   â”œâ”€ For each month:
   â”‚   â”œâ”€ Count reviews
   â”‚   â”œâ”€ Average sentiment
   â”‚   â””â”€ Average rating
   â”‚
   â””â”€ Compare first half vs second half:
       â”œâ”€ If diff > 0.1 â†’ "improving"
       â”œâ”€ If diff < -0.1 â†’ "declining"
       â””â”€ Else â†’ "stable"

5. Call LLM: generate_pattern_analysis()
   â”œâ”€ Input: business info, stats, themes, trends
   â””â”€ Output: PatternAnalysisResult
       â”œâ”€ health_score (0-100)
       â”œâ”€ health_grade (A+ to F)
       â”œâ”€ health_breakdown (by theme)
       â”œâ”€ overall_sentiment
       â”œâ”€ trend_direction
       â”œâ”€ SWOT (strengths, weaknesses, opportunities, threats)
       â”œâ”€ critical_issues (with severity, suggested actions)
       â”œâ”€ delighters (exceeds expectations)
       â””â”€ pain_points (frustrations)

6. Create Analysis node
   â””â”€ Store all analysis data

7. Create Theme nodes
   â”œâ”€ For each theme with >= 3 mentions:
   â”‚   â””â”€ Create Theme node with:
   â”‚       - name, category
   â”‚       - mention_count
   â”‚       - sentiment breakdown
   â”‚       - sub_themes
   â”‚       - sample quotes
   â”‚
   â””â”€ Connect: Business ++> Theme
```

**LLM Call**: `generate_pattern_analysis()`

**Output**:

- `analysis: Analysis` - Analysis node reference
- `themes_created: int` - Number of Theme nodes created
- `status: str` - "completed"

---

#### **Agent 4: ReportGeneratorAgent**

**Purpose**: Generate executive report with recommendations

**Process**:

```
1. Find target Business node
   â””â”€ Get Analysis node

2. Get themes
   â””â”€ Business --> Theme nodes

3. Call LLM: generate_report_content()
   â”œâ”€ Input:
   â”‚   - Business details
   â”‚   - Health score, grade
   â”‚   - Sentiment data
   â”‚   - SWOT analysis
   â”‚   - Critical issues
   â”‚   - Theme analysis
   â”‚   - Trend data
   â”‚
   â””â”€ Output: ReportGenerationResult
       â”œâ”€ headline (5-10 words)
       â”œâ”€ one_liner (single sentence)
       â”œâ”€ key_metric (most important metric)
       â”œâ”€ executive_summary (2-3 paragraphs)
       â”œâ”€ key_findings (5-15 findings)
       â”œâ”€ recommendations_immediate (this week)
       â”œâ”€ recommendations_short_term (this month)
       â””â”€ recommendations_long_term (this quarter)

4. Create Report node
   â”œâ”€ Store all report content
   â””â”€ Connect: Business ++> Report
```

**LLM Call**: `generate_report_content()`

**Output**:

- `report: Report` - Report node reference
- `status: str` - "completed"

---

## ğŸ—„ï¸ Data Model (Graph Structure)

### Node Types

```
Root
 â”‚
 â””â”€â”€ Business
      â”œâ”€â”€ Review (multiple)
      â”œâ”€â”€ Theme (multiple)
      â”œâ”€â”€ Analysis (one)
      â””â”€â”€ Report (one)
```

### Node Details

#### **Business Node**

```jac
node Business {
    has place_id: str;
    has data_id: str;
    has name: str;
    has business_type: str;                # From Google
    has business_type_normalized: str;     # Our mapping
    has address: str;
    has phone: str;
    has website: str;
    has rating: float;
    has total_reviews: int;
    has price_level: str;
    has latitude: float;
    has longitude: float;
    has opening_hours: dict;
    has photos_count: int;
    has status: str;                       # "pending" | "fetching" | "fetched"
}
```

#### **Review Node**

```jac
node Review {
    has review_id: str;
    has author: str;
    has rating: int;
    has text: str;
    has date: str;
    has relative_date: str;

    # Analysis results (populated by SentimentAnalyzer)
    has sentiment: str;              # "positive" | "negative" | "neutral" | "mixed"
    has sentiment_score: float;      # -1.0 to 1.0
    has themes: list[str];           # Main themes
    has sub_themes: dict;            # {theme: [sub-themes]}
    has keywords: list[str];         # Key phrases
    has emotion: str;                # Primary emotion
    has analyzed: bool;
}
```

#### **Theme Node**

```jac
node Theme {
    has name: str;
    has mention_count: int;
    has positive_count: int;
    has negative_count: int;
    has neutral_count: int;
    has avg_sentiment: float;
    has sub_themes: list[dict];      # [{name, mentions, sentiment, verdict}]
    has sample_quotes_positive: list[str];
    has sample_quotes_negative: list[str];
}
```

#### **Analysis Node**

```jac
node Analysis {
    has analysis_id: str;
    has created_at: str;
    has reviews_analyzed: int;

    # Health Score
    has health_score: int;           # 0-100
    has health_grade: str;           # A+ to F
    has health_breakdown: dict;      # {theme: score}

    # Confidence
    has confidence_level: str;       # "low" | "medium" | "high"

    # Sentiment
    has overall_sentiment: str;
    has sentiment_score: float;
    has positive_count: int;
    has negative_count: int;
    has neutral_count: int;
    has positive_percentage: float;
    has negative_percentage: float;

    # SWOT
    has strengths: list[dict];
    has weaknesses: list[dict];
    has opportunities: list[dict];
    has threats: list[dict];

    # Issues
    has critical_issues: list[dict];
    has pain_points: list[str];
    has delighters: list[str];

    # Trends
    has trend_direction: str;        # "improving" | "stable" | "declining"
    has monthly_breakdown: list[dict];
    has theme_trends: list[dict];

    # Statistics
    has rating_distribution: dict;
    has avg_review_length: int;
    has response_rate: float;
}
```

#### **Report Node**

```jac
node Report {
    has report_id: str;
    has report_type: str;
    has created_at: str;

    # Executive Summary
    has headline: str;
    has one_liner: str;
    has key_metric: str;
    has executive_summary: str;

    # Findings & Recommendations
    has key_findings: list[str];
    has recommendations_immediate: list[dict];
    has recommendations_short_term: list[dict];
    has recommendations_long_term: list[dict];
}
```

### Edge Types

```jac
edge HasReview {
    has fetched_at: str;
}

edge HasTheme {
    has relevance_score: float;
}

edge HasAnalysis {
    has version: int;
}

edge HasReport {
    has version: int;
}
```

---

## ğŸ”„ Data Flow Summary

```
1. User Input
   â””â”€â–¶ AnalyzeUrl Walker

2. URL Parsing
   â””â”€â–¶ data_id extracted

3. Data Fetching (SERP API or Mock)
   â””â”€â–¶ Business + Reviews created

4. Business Type Detection
   â””â”€â–¶ Mapped to normalized type

5. Batch Sentiment Analysis (5 at a time)
   â””â”€â–¶ Reviews updated with sentiment, themes

6. Statistical Calculations
   â””â”€â–¶ Stats dict built

7. Theme Analysis
   â””â”€â–¶ Themes + sub-themes with sentiment

8. Trend Calculation
   â””â”€â–¶ Monthly breakdown, trend direction

9. LLM Pattern Analysis
   â””â”€â–¶ Health score, SWOT, critical issues

10. Theme Nodes Created
    â””â”€â–¶ Connected to Business

11. LLM Report Generation
    â””â”€â–¶ Executive summary, recommendations

12. Report Node Created
    â””â”€â–¶ Connected to Business

13. Output JSON Built
    â””â”€â–¶ Returned to user
```

---

## ğŸ¯ Key Design Decisions

### 1. Batch Processing

- **Why**: Reduce LLM API calls (20 reviews = 4 calls instead of 20)
- **Trade-off**: Slightly more complex prompt management

### 2. Business Type Detection

- **Why**: Enables business-specific theme analysis
- **Example**: Hotels analyze "Room Quality", Restaurants analyze "Food Quality"

### 3. Sub-themes

- **Why**: Granular insights (e.g., "Service" â†’ "Speed", "Friendliness")
- **Benefit**: Actionable recommendations

### 4. Health Score

- **Why**: Simple metric for executives
- **Calculation**: Based on theme sentiments + overall sentiment

### 5. Trend Analysis

- **Why**: Identify if business is improving or declining
- **Method**: Compare first half vs second half of review period

### 6. Confidence Levels

- **Why**: Indicate reliability of insights
- **Thresholds**:
  - Low: < 20 reviews
  - Medium: 20-50 reviews
  - High: > 50 reviews

---

## ğŸš€ Scalability Considerations

### Current System (Jac)

- **In-memory graph**: Fast but not persistent across runs
- **Sequential agents**: Simple but not parallel

### For Production (Node.js)

- **Database**: PostgreSQL with proper indexes
- **Caching**: Redis for API responses
- **Queue**: BullMQ for async processing
- **Parallel**: Process batches in parallel
- **Rate limiting**: Handle API rate limits

---

**Next**: Read [02-DATA-FETCHING.md](./02-DATA-FETCHING.md) for detailed data fetching process.
